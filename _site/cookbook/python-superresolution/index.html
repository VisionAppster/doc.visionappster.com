
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Super-resolution with OpenCV and Python &mdash; VisionAppster  documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/docsearch.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/v.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script defer="defer" src="../../_static/js/docsearch.min.js"></script>
        <script defer="defer" src="../../_static/js/algolia.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" />
    <link rel="next" title="Yolo V4 object detection with OpenCV and Python" href="../python-yolov4/" />
    <link rel="prev" title="OpenCv Tools" href="../opencv-tools/" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <div data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search" >
        

        
          <a href="../../">
        

        
          
          <img src="../../_static/visionappster.png" class="logo" alt="Logo">
        
        </a>

        
          
          
        

        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

        
      </div>

      <nav class="wy-nav-side-inner">
        <div class="wy-side-scroll">
          
          <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
            
              
              
                
              
              
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install/">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../engine/">Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../builder/">Builder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tools/">Built-in tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../components/">Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cameras/">Cameras</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../">Cookbook</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../analyze-blob-geometry/">Analyze Blob Geometry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../binarize/">Binarize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blurring/">Blurring</a></li>
<li class="toctree-l2"><a class="reference internal" href="../caliper/">Caliper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../code-reading/">Code reading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contour-matching/">Contour matching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../detect-blobs/">Detect Blobs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../image-classifier/">Image classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../manual-calibration/">Manual Calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../motion-detector/">Motion detector</a></li>
<li class="toctree-l2"><a class="reference internal" href="../opencv-tools/">OpenCv Tools</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Super-resolution with OpenCV and Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloads">Downloads</a></li>
<li class="toctree-l3"><a class="reference internal" href="#detailed-description">Detailed description</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#setting-up-the-environment">Setting up the environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#python-code-walk-through">Python code walk-through</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-the-tool-in-the-builder">Using the tool in the Builder</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python-yolov4/">Yolo V4 object detection with OpenCV and Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../qr-positioning/">Positioning with QR codes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../raspi-code-reading/">Code reading for Raspberry Pi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../texture-matching/">Texture matching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../unsharp-masking/">Unsharp Masking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../web-app/">Web app</a></li>
<li class="toctree-l2"><a class="reference internal" href="../white-balance/">White Balance Correction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../yolo-classifier/">YOLO classifier</a></li>
</ul>
</li>
</ul>

              
            
          </div>
          
        </div>
      </nav>
    </div>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../">VisionAppster</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../">Cookbook</a> &raquo;</li>
        
      <li>Super-resolution with OpenCV and Python</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="super-resolution-with-opencv-and-python">
<h1>Super-resolution with OpenCV and Python<a class="headerlink" href="#super-resolution-with-opencv-and-python" title="Permalink to this headline">🔗</a></h1>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">🔗</a></h2>
<p>This recipe describes how you can make a Python tool which uses OpenCV
functions and deep neural networks for image analysis. The tool scales a
small image up while trying to preserve details.</p>
</div>
<div class="section" id="downloads">
<h2>Downloads<a class="headerlink" href="#downloads" title="Permalink to this headline">🔗</a></h2>
<ul class="simple">
<li><p><a class="reference download internal" download="" href="../../_downloads/8522243e5a7b070f7ea2cd0af1dcce0c/CookbookPythonSuperresolution.zip"><code class="xref download docutils literal notranslate"><span class="pre">Project</span> <span class="pre">file</span></code></a></p></li>
<li><p><a class="reference download internal" download="" href="../../_downloads/d6b4a2614ec85991a41827699079069d/rescale_toolplugin.py"><code class="xref download docutils literal notranslate"><span class="pre">Python</span> <span class="pre">tool</span> <span class="pre">plugin</span></code></a>.</p></li>
<li><p><a class="reference external" href="https://github.com/fannymonori/TF-LapSRN/tree/master/export">LapSRN
models</a></p></li>
</ul>
</div>
<div class="section" id="detailed-description">
<h2>Detailed description<a class="headerlink" href="#detailed-description" title="Permalink to this headline">🔗</a></h2>
<div class="section" id="setting-up-the-environment">
<h3>Setting up the environment<a class="headerlink" href="#setting-up-the-environment" title="Permalink to this headline">🔗</a></h3>
<p>As explained in <a class="reference internal" href="../../api/python/tool/"><span class="doc">Python tool API</span></a>, the Builder will
execute all Python modules whose name ends with <code class="docutils literal notranslate"><span class="pre">*toolplugin.py</span></code> in
<code class="docutils literal notranslate"><span class="pre">$HOME/VisionAppster/plugins/tool/</span></code>. If these modules register tools,
they will appear in Builder’s tool box. In this example, the Python
module will be
<a class="reference download internal" download="" href="../../_downloads/d6b4a2614ec85991a41827699079069d/rescale_toolplugin.py"><code class="xref download docutils literal notranslate"><span class="pre">rescale_toolplugin.py</span></code></a> and the name
of the tool in the plugin is <code class="docutils literal notranslate"><span class="pre">Rescale</span></code>.</p>
<p>The Rescale tool uses a deep neural network (DNN) to zoom up an image
with enhanced resolution. The DNN is first used for zooming up in steps
of powers of 2 and finally adjusting the size with OpenCV’s <code class="docutils literal notranslate"><span class="pre">resize</span></code>
function to match the required zoom factor. The DNN data can be
downloaded from
<a class="reference external" href="https://github.com/fannymonori/TF-LapSRN/tree/master/export">github</a>.
The Python code searches for the DNN data files (<code class="docutils literal notranslate"><span class="pre">LapSRN_x*.pb</span></code>) in a
directory called <code class="docutils literal notranslate"><span class="pre">superresolution</span></code> under the directory the Python
module itself is stored in, so you must copy the data files to
<code class="docutils literal notranslate"><span class="pre">$HOME/VisionAppster/plugins/tool/superresolution</span></code> as shown below.</p>
<div class="medium figure align-default" id="id1">
<img alt="Python code and DNN data files" src="../../_images/superresolution-5.png" />
<p class="caption"><span class="caption-text">Python code and DNN data files</span><a class="headerlink" href="#id1" title="Permalink to this image">🔗</a></p>
</div>
<p>Should you want to experiment with superresolution models other than
<em>LapSRN</em>, the DNN files and further information can be found
<a class="reference external" href="https://github.com/opencv/opencv_contrib/tree/master/modules/dnn_superres">here</a>.</p>
<p>Use the <a class="reference internal" href="../../components/installing/"><span class="doc">va-pkg command-line tool</span></a> to install
the required NumPy and OpenCV packages:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>va-pkg install python:numpy python:opencv-python python:opencv-contrib-python
</pre></div>
</div>
</div>
<div class="section" id="python-code-walk-through">
<h3>Python code walk-through<a class="headerlink" href="#python-code-walk-through" title="Permalink to this headline">🔗</a></h3>
<p>Let us walk through <a class="reference download internal" download="" href="../../_downloads/d6b4a2614ec85991a41827699079069d/rescale_toolplugin.py"><code class="xref download docutils literal notranslate"><span class="pre">the</span> <span class="pre">python</span>
<span class="pre">code</span></code></a>.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">visionappster</span> <span class="k">as</span> <span class="nn">va</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">cv2</span> <span class="kn">import</span> <span class="n">dnn_superres</span>
<span class="kn">import</span> <span class="nn">os</span>
</pre></div>
</div>
<p>Import the necessary modules. <code class="docutils literal notranslate"><span class="pre">visionappster</span></code> is needed in every
Python tool, <code class="docutils literal notranslate"><span class="pre">numpy</span></code> almost as often. <code class="docutils literal notranslate"><span class="pre">cv2</span></code> is the name of the
OpenCV module. <code class="docutils literal notranslate"><span class="pre">os</span></code> is needed for path manipulation.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Rescale</span><span class="p">:</span>
    <span class="c1"># Shared by all instances of this class</span>
    <span class="n">_sr_dict</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_load_superresolution_models</span><span class="p">():</span>
        <span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;/superresolution/&#39;</span>
        <span class="k">for</span> <span class="n">scale</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">):</span>
            <span class="n">Rescale</span><span class="o">.</span><span class="n">_sr_dict</span><span class="p">[</span><span class="n">scale</span><span class="p">]</span> <span class="o">=</span> <span class="n">dnn_superres</span><span class="o">.</span><span class="n">DnnSuperResImpl_create</span><span class="p">()</span>
            <span class="n">Rescale</span><span class="o">.</span><span class="n">_sr_dict</span><span class="p">[</span><span class="n">scale</span><span class="p">]</span><span class="o">.</span><span class="n">readModel</span><span class="p">(</span><span class="n">data_dir</span> <span class="o">+</span> <span class="s1">&#39;LapSRN_x&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.pb&#39;</span><span class="p">)</span>
            <span class="n">Rescale</span><span class="o">.</span><span class="n">_sr_dict</span><span class="p">[</span><span class="n">scale</span><span class="p">]</span><span class="o">.</span><span class="n">setModel</span><span class="p">(</span><span class="s1">&#39;lapsrn&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">Rescale</span><span class="o">.</span><span class="n">_sr_dict</span><span class="p">:</span>
            <span class="n">Rescale</span><span class="o">.</span><span class="n">_load_superresolution_models</span><span class="p">()</span>
</pre></div>
</div>
<p>Initialization: a super-resolution object is created and the neural net
models are loaded. The name of the class, <code class="docutils literal notranslate"><span class="pre">Rescale</span></code>, will show up as
the name of the tool in the Builder. Since the DNN models are not
modified at run time, they are only loaded once and shared between all
instances of the tool class.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">inputs</span><span class="p">:</span> <span class="p">[(</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">.</span><span class="n">Image</span><span class="p">,</span> <span class="n">va</span><span class="o">.</span><span class="n">Image</span><span class="p">()),</span>
                     <span class="p">(</span><span class="s1">&#39;zoomFactor&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">})],</span>
            <span class="n">outputs</span><span class="p">:</span> <span class="p">[(</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">.</span><span class="n">Image</span><span class="p">)]):</span>
</pre></div>
</div>
<p>This declares the tool’s public interface. It has two inputs:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">image</span></code> is the input image. Its type is <code class="docutils literal notranslate"><span class="pre">va.Image</span></code>, which is the
standard data type for images passed between tools. As you’ll see
later, conversions to other data types are straightforward. The
default value of the input parameter is an empty image and must be
changed by the user of the tool.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">zoomFactor</span></code> determines how much the image is zoomed in X- and
Y-directions. For example, if <code class="docutils literal notranslate"><span class="pre">zoomFactor</span></code> = 3, the size of the
output image will be 3*3=9 times the size of the input. The default
value is 1 (i.e. no change). The value must be positive.</p></li>
</ul>
<p>The output is also called <code class="docutils literal notranslate"><span class="pre">image</span></code>, and its type is <code class="docutils literal notranslate"><span class="pre">va.Image</span></code>.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">inputs</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">is_empty</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Input image must be non-empty.&#39;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">inputs</span><span class="o">.</span><span class="n">zoomFactor</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Zoom factor must be greater than zero.&#39;</span><span class="p">)</span>

<span class="c1"># VA image to numpy array</span>
<span class="n">np_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">to_rgb</span><span class="p">(),</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The first step is to ensure valid input. An empty image can not be
scaled and a non-positive zoom factor is equally invalid.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">va.Image</span></code> (and other array-like types like <code class="docutils literal notranslate"><span class="pre">va.Matrix</span></code> and
<code class="docutils literal notranslate"><span class="pre">va.Tensor</span></code>) implement the Python buffer protocol and can therefore be
used as NumPy arrays without copying the data. Passing <code class="docutils literal notranslate"><span class="pre">copy=False</span></code> to
<code class="docutils literal notranslate"><span class="pre">np.array</span></code> creates a shallow copy.</p>
<p>The input for the superresolution DNN must be a color image. If the
input is a gray-scale image, <code class="docutils literal notranslate"><span class="pre">to_rgb</span></code> copies the intensity to the red,
green and blue color channels. Now the shape of the image array
<code class="docutils literal notranslate"><span class="pre">np_img</span></code> is (rows, columns, 3).</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np_img</span><span class="o">.</span><span class="n">shape</span>
<span class="n">zoom_factor</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">zoomFactor</span>

<span class="c1"># Maximum number of pixels in the output image</span>
<span class="n">max_pixels</span> <span class="o">=</span> <span class="mf">4.0</span> <span class="o">*</span> <span class="mi">2</span><span class="o">**</span><span class="mi">20</span>
<span class="c1"># Actual number of pixels before limiter</span>
<span class="n">pixels</span> <span class="o">=</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">cols</span> <span class="o">*</span> <span class="p">(</span><span class="n">zoom_factor</span> <span class="o">*</span> <span class="n">zoom_factor</span><span class="p">)</span>
<span class="n">overshoot</span> <span class="o">=</span> <span class="n">pixels</span> <span class="o">/</span> <span class="n">max_pixels</span>

<span class="c1"># Limit the zoom factor so that the output image has</span>
<span class="c1"># no more than max_pixels pixels.</span>
<span class="k">if</span> <span class="n">overshoot</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">zoom_factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_pixels</span> <span class="o">/</span> <span class="p">(</span><span class="n">rows</span> <span class="o">*</span> <span class="n">cols</span><span class="p">))</span> <span class="o">**</span> <span class="mf">0.5</span>
</pre></div>
</div>
<p>This copies the zoom factor from input arguments to a local variable and
makes a sanity check to it. If the factor is so big that the output
image would be larger than 16 megapixels, adjust the factor so that
output image size will be 16 Mpix.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="c1"># List of zoom factors to be applied by DNN</span>
<span class="n">power2list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">while</span> <span class="n">zoom_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">zoom_factor</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">power2list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">zoom_factor</span> <span class="o">=</span> <span class="n">zoom_factor</span> <span class="o">/</span> <span class="mf">8.0</span>
    <span class="k">elif</span> <span class="n">zoom_factor</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">power2list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">zoom_factor</span> <span class="o">=</span> <span class="n">zoom_factor</span> <span class="o">/</span> <span class="mf">4.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">power2list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">zoom_factor</span> <span class="o">=</span> <span class="n">zoom_factor</span> <span class="o">/</span> <span class="mf">2.0</span>
</pre></div>
</div>
<p>Break the zoom factor into a product sequence of powers of two. The
result of this while loop is list <code class="docutils literal notranslate"><span class="pre">power2list</span></code> where each element is
2, 4 or 8. The list will be empty if <code class="docutils literal notranslate"><span class="pre">zoom_factor</span></code> &gt; 1. After the
loop, <code class="docutils literal notranslate"><span class="pre">zoom_factor</span></code> will be in the half-open range (0…1].</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">power2list</span><span class="p">:</span>
    <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sr_obj</span><span class="p">[</span><span class="n">z</span><span class="p">]</span><span class="o">.</span><span class="n">upsample</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
<p>This is where the magic happens. For each element <code class="docutils literal notranslate"><span class="pre">z</span></code> in
<code class="docutils literal notranslate"><span class="pre">power2list</span></code>, run one of the preloaded models (“LapSRN_X.bp”) to zoom
the image up by the corresponding factor.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="c1"># Scale down by the zoom_factor (which is &lt;= 1)</span>
<span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np_img</span><span class="o">.</span><span class="n">shape</span>
<span class="k">if</span> <span class="n">zoom_factor</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">np_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">np_img</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">cols</span> <span class="o">*</span> <span class="n">zoom_factor</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">rows</span> <span class="o">*</span> <span class="n">zoom_factor</span><span class="p">)))</span>
</pre></div>
</div>
<p>If the scaling factor was not a power of two, the size of the upscaled
image needs to be adjusted down. This happens by calling OpenCV’s
<code class="docutils literal notranslate"><span class="pre">resize()</span></code> function.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert NumPy array to an image.</span>
<span class="n">outputs</span><span class="o">.</span><span class="n">image</span> <span class="o">=</span> <span class="n">va</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="n">va</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">RGB32</span><span class="p">,</span> <span class="n">np_img</span><span class="p">)</span>
<span class="c1"># The scaled image represents the same piece of world as the input</span>
<span class="c1"># image, just with a different resolution. This aligns the output image</span>
<span class="c1"># according to the input so that subsequent analysis steps know its</span>
<span class="c1"># exact position.</span>
<span class="n">outputs</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">align_with</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
<p>The final step is to copy the NumPy array to a <code class="docutils literal notranslate"><span class="pre">va.Image</span></code> and place it
to output arguments. The <code class="docutils literal notranslate"><span class="pre">align_with</span></code> call is needed to adjust the
coordinate system of the output image so that subsequent analysis steps
can correctly transform coordinates between its pixel coordinates and
the world coordinate system. The <a class="reference internal" href="../python-yolov4/"><span class="doc">Yolo
cookbook</span></a> illustrates why this is important.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">va</span><span class="o">.</span><span class="n">Tool</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="s1">&#39;com.visionappster.opencvpython/1&#39;</span><span class="p">,</span> <span class="n">Rescale</span><span class="p">)</span>
</pre></div>
</div>
<p>This publishes the tool to the VisionAppster runtime. The unique
component ID of tools in this Python plugin is
<code class="docutils literal notranslate"><span class="pre">com.visionappster.opencvpython/1</span></code>, where “1” denotes a major version
number.</p>
</div>
<div class="section" id="using-the-tool-in-the-builder">
<h3>Using the tool in the Builder<a class="headerlink" href="#using-the-tool-in-the-builder" title="Permalink to this headline">🔗</a></h3>
<p>Once you save the Python file in
<code class="docutils literal notranslate"><span class="pre">$HOME/VisionAppster/plugins/tool/rescale_toolplugin.py</span></code> and start the
Builder (or click the “Refresh user plugins” button if the Builder is
already running), you’ll see the new tool in the tool box:</p>
<div class="medium figure align-default" id="id2">
<img alt="The new tool in the tool box" src="../../_images/superresolution-4.png" />
<p class="caption"><span class="caption-text">The new tool in the tool box</span><a class="headerlink" href="#id2" title="Permalink to this image">🔗</a></p>
</div>
<p>Let’s make a simple application which uses the tool. The image coming
from the Image Source is first deliberately scaled down by a factor of
two with <a class="reference internal" href="../../tools/BinPixelsTool/"><span class="doc">Scale Image</span></a>, then zoomed up by a
factor of ten.</p>
<div class="small figure align-default" id="id3">
<img alt="The complete app" src="../../_images/superresolution-1.png" />
<p class="caption"><span class="caption-text">The complete app</span><a class="headerlink" href="#id3" title="Permalink to this image">🔗</a></p>
</div>
<p>This is the original test image</p>
<div class="medium figure align-default" id="id4">
<img alt="Pena, our standard test image" src="../../_images/pena.png" />
<p class="caption"><span class="caption-text">Pena, our standard test image</span><a class="headerlink" href="#id4" title="Permalink to this image">🔗</a></p>
</div>
<p>The picture zoomed with super-resolution (lower image) is slightly
better compared to traditional bilinear zooming (upper image).</p>
<p>The difference becomes more obvious by zooming into details.</p>
<div class="medium figure align-default" id="id5">
<img alt="After bilinear upscaling" src="../../_images/superresolution-2.png" />
<p class="caption"><span class="caption-text">After bilinear upscaling</span><a class="headerlink" href="#id5" title="Permalink to this image">🔗</a></p>
</div>
<div class="medium figure align-default" id="id6">
<img alt="After super-resolution upscaling" src="../../_images/superresolution-3.png" />
<p class="caption"><span class="caption-text">After super-resolution upscaling</span><a class="headerlink" href="#id6" title="Permalink to this image">🔗</a></p>
</div>
<div class="medium figure align-default" id="id7">
<img alt="Bilinear upscaling details" src="../../_images/superresolution-6.png" />
<p class="caption"><span class="caption-text">Bilinear upscaling details</span><a class="headerlink" href="#id7" title="Permalink to this image">🔗</a></p>
</div>
<div class="medium figure align-default" id="id8">
<img alt="Super-resolution upscaling details" src="../../_images/superresolution-7.png" />
<p class="caption"><span class="caption-text">Super-resolution upscaling details</span><a class="headerlink" href="#id8" title="Permalink to this image">🔗</a></p>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../python-yolov4/" class="btn btn-neutral float-right" title="Yolo V4 object detection with OpenCV and Python" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../opencv-tools/" class="btn btn-neutral float-left" title="OpenCv Tools" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, VisionAppster.

    </p>
  </div> 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-129514554-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>